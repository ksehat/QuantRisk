[2021-07-08 14:18:34,221] [AI INFO] [ai:44] Job start to run.
[2021-07-08 14:18:34,221] [AI INFO] [ai:44] data type is TimeSeries
[2021-07-08 14:18:34,221] [AI INFO] [ai:44] data type is Classification
[2021-07-08 14:18:34,446] [AI INFO] [ai:44] <module 'qr_time_series_data_container.time_series_container' from 'E:\\ai-services-v2_1\\env\\lib\\site-packages\\qr_time_series_data_container\\time_series_container.py'>
[2021-07-08 14:18:34,446] [AI INFO] [ai:44] time series container imported
[2021-07-08 14:18:37,790] [AI INFO] [ai:44] data processing created.
[2021-07-08 14:18:37,790] [AI DEBUG] [ai:44] Handle pretrained model.
[2021-07-08 14:18:37,790] [AI DEBUG] [ai:44] inserting into real-time mode ...
[2021-07-08 14:18:39,272] [AI DEBUG] [ai:44] A new <class 'abc.ABCMeta'> created by attributes => data= <qr_time_series_data_container.time_series_container.TimeSeriesContainerClassification object at 0x00000202C185E888>, \
                            config = {'draw2dStructure': [{'type': 'VerticalLayout', 'id': '123a71f6-989b-4440-81a4-b02e0c4db40d', 'x': 20, 'y': 20, 'width': 78.546875, 'height': 57.25, 'alpha': 1, 'selectable': False, 'draggable': False, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the Data Frame, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: Input, InputLayer, inputLayer \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'DataFrame', 'class_name': 'DataFrame', 'config': {'batch_input_shape': [], 'dtype': 'float32', 'sparse': False, 'name': 'DataFrame'}, 'inbound_nodes': []}, 'id': '123a71f6-989b-4440-81a4-b02e0c4db40d', 'type': 'DataFrame'}, 'cssClass': 'labelModel', 'ports': [{'type': 'draw2d.OutputPort', 'id': 'aa13c264-70f0-47fc-ae9e-5c00eba1dc66', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_OutputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 100, 'name': 'output', 'semanticGroup': 'global', 'port': 'draw2d.OutputPort', 'locator': 'draw2d.layout.locator.OutputPortLocator', 'locatorAttr': {}}], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 1, 'radius': 5, 'dasharray': None, 'gap': 0, 'labels': [{'type': 'TooltipFigure', 'id': '2f4fd90c-431d-046b-5344-ba738fce8252', 'x': 0, 'y': 1, 'width': 78.546875, 'height': 29.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'labelModelHeader', 'ports': [], 'bgColor': 'rgba(3,102,214,1)', 'color': 'rgba(255,255,255,1)', 'stroke': 0, 'radius': 6, 'dasharray': None, 'text': 'DataFrame', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(255,255,255,1)', 'fontFamily': None}, {'type': 'TooltipFigure', 'id': '123a71f6-989b-4440-81a4-b02e0c4db40d', 'x': 0, 'y': 30.625, 'width': 78.546875, 'height': 25.625, 'alpha': 1, 'selectable': False, 'draggable': False, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the Data Frame, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: Input, InputLayer, inputLayer \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'DataFrame', 'class_name': 'DataFrame', 'config': {'batch_input_shape': [], 'dtype': 'float32', 'sparse': False, 'name': 'DataFrame'}, 'inbound_nodes': []}, 'id': '123a71f6-989b-4440-81a4-b02e0c4db40d', 'type': 'DataFrame'}, 'cssClass': 'TooltipFigure', 'ports': [], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 0, 'radius': 5, 'dasharray': None, 'text': 'Input', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(0,0,0,1)', 'fontFamily': None}]}, {'type': 'VerticalLayout', 'id': 'e435eebb-c80a-454f-8377-04a7194a2468', 'x': 590.5250244140625, 'y': 100.15000915527344, 'width': 83.765625, 'height': 57.25, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 5, 'activation': 'relu', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'id': 'e435eebb-c80a-454f-8377-04a7194a2468', 'model': {'title': 'Dense', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#00796B', 'nodeData': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 1, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}}}, 'header': 'Core Layers'}, 'cssClass': 'labelModel', 'ports': [{'type': 'draw2d.InputPort', 'id': 'e435eebb-c80a-454f-8377-04a7194a2468undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_InputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 1, 'name': 'input0', 'semanticGroup': 'global', 'port': 'draw2d.InputPort', 'locator': 'draw2d.layout.locator.InputPortLocator', 'locatorAttr': {}}, {'type': 'draw2d.OutputPort', 'id': 'e435eebb-c80a-454f-8377-04a7194a2468undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_OutputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 100, 'name': 'output', 'semanticGroup': 'global', 'port': 'draw2d.OutputPort', 'locator': 'draw2d.layout.locator.OutputPortLocator', 'locatorAttr': {}}], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 1, 'radius': 5, 'dasharray': None, 'gap': 0, 'labels': [{'type': 'TooltipFigure', 'id': '900b6c6c-f2df-ca7b-c5ec-8fb9dcbe71a7', 'x': 0, 'y': 1, 'width': 83.765625, 'height': 29.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'labelModelHeader', 'ports': [], 'bgColor': 'rgba(3,102,214,1)', 'color': 'rgba(255,255,255,1)', 'stroke': 0, 'radius': 6, 'dasharray': None, 'text': 'Core Layers', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(255,255,255,1)', 'fontFamily': None}, {'type': 'TooltipFigure', 'id': 'e435eebb-c80a-454f-8377-04a7194a2468', 'x': 0, 'y': 30.625, 'width': 83.765625, 'height': 25.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'id': 'e435eebb-c80a-454f-8377-04a7194a2468', 'model': {'title': 'Dense', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#00796B', 'nodeData': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 1, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}}}, 'header': 'Core Layers'}, 'cssClass': 'TooltipFigure', 'ports': [], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 0, 'radius': 5, 'dasharray': None, 'text': 'Dense', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(0,0,0,1)', 'fontFamily': None}]}, {'type': 'VerticalLayout', 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4', 'x': 745.5250244140625, 'y': 118.15000915527344, 'width': 83.765625, 'height': 57.25, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense2', 'units': 1, 'activation': 'softmax', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4', 'model': {'title': 'Dense', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#00796B', 'nodeData': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 1, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}}}, 'header': 'Core Layers'}, 'cssClass': 'labelModel', 'ports': [{'type': 'draw2d.InputPort', 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_InputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 1, 'name': 'input0', 'semanticGroup': 'global', 'port': 'draw2d.InputPort', 'locator': 'draw2d.layout.locator.InputPortLocator', 'locatorAttr': {}}, {'type': 'draw2d.OutputPort', 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_OutputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 100, 'name': 'output', 'semanticGroup': 'global', 'port': 'draw2d.OutputPort', 'locator': 'draw2d.layout.locator.OutputPortLocator', 'locatorAttr': {}}], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 1, 'radius': 5, 'dasharray': None, 'gap': 0, 'labels': [{'type': 'TooltipFigure', 'id': '304bccaf-cc81-fb34-206c-74bb4fedf54c', 'x': 0, 'y': 1, 'width': 83.765625, 'height': 29.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'labelModelHeader', 'ports': [], 'bgColor': 'rgba(3,102,214,1)', 'color': 'rgba(255,255,255,1)', 'stroke': 0, 'radius': 6, 'dasharray': None, 'text': 'Core Layers', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(255,255,255,1)', 'fontFamily': None}, {'type': 'TooltipFigure', 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4', 'x': 0, 'y': 30.625, 'width': 83.765625, 'height': 25.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'id': 'f67845b6-0fe9-47c2-8239-763e482fedc4', 'model': {'title': 'Dense', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#00796B', 'nodeData': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 1, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore.\nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace.\nThese are valid names: final, Dense01, dense1  \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 1, 'help': 'The number of units (hidden neurons) in the layer. Remember that if this layer is the final layer, the number of hidden units should be equal to size of output, for example in case of a single regression it should be 1, and in case of classification it should be equal to the number of classes.\nFor load and price forecast recommended value is 80, higher numbers may cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'linear', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk.\n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 1, 'activation': 'linear', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0}, 'inbound_nodes': [[]]}}}, 'header': 'Core Layers'}, 'cssClass': 'TooltipFigure', 'ports': [], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 0, 'radius': 5, 'dasharray': None, 'text': 'Dense2', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(0,0,0,1)', 'fontFamily': None}]}, {'type': 'VerticalLayout', 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'x': 409.5250244140625, 'y': 107.45001220703125, 'width': 110.453125, 'height': 57.25, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}, 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'model': {'title': 'LSTM', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#FFC107', 'nodeData': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 10, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}}}, 'header': 'Recurrent Layers'}, 'cssClass': 'labelModel', 'ports': [{'type': 'draw2d.InputPort', 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_InputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 10, 'name': 'input0', 'semanticGroup': 'global', 'port': 'draw2d.InputPort', 'locator': 'draw2d.layout.locator.InputPortLocator', 'locatorAttr': {}}, {'type': 'draw2d.OutputPort', 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7undefined', 'width': 10, 'height': 10, 'alpha': 1, 'selectable': False, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_OutputPort', 'bgColor': 'rgba(79,104,112,1)', 'color': 'rgba(27,27,27,1)', 'stroke': 1, 'dasharray': None, 'maxFanOut': 100, 'name': 'output', 'semanticGroup': 'global', 'port': 'draw2d.OutputPort', 'locator': 'draw2d.layout.locator.OutputPortLocator', 'locatorAttr': {}}], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 1, 'radius': 5, 'dasharray': None, 'gap': 0, 'labels': [{'type': 'TooltipFigure', 'id': 'a1d5c1d7-0704-a9b3-0eb5-751bf5abfce8', 'x': 0, 'y': 1, 'width': 110.453125, 'height': 29.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'labelModelHeader', 'ports': [], 'bgColor': 'rgba(3,102,214,1)', 'color': 'rgba(255,255,255,1)', 'stroke': 0, 'radius': 6, 'dasharray': None, 'text': 'Recurrent Layers', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(255,255,255,1)', 'fontFamily': None}, {'type': 'TooltipFigure', 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'x': 0, 'y': 30.625, 'width': 110.453125, 'height': 25.625, 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}, 'id': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'model': {'title': 'LSTM', 'isArray': False, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'color': '#FFC107', 'nodeData': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}, 'data': {'multiple': True, 'inputFan': 10, 'outputFan': 100, 'layout': [{'name': 'name', 'data': {'type': 'text', 'default': '', 'help': "Name of the layer, use names without whitespace, instead of whitespace use underscore. \nWe recommended to keep the system provided default names for consitency. The name should just consist of lower and upper case letters and numbers without whitespace. \nThese are valid names: lstm1, LSTM01. \nNote that Layer's name should be UNIQUE.", 'url': '', 'regex': '', 'label': 'Name', 'dependsOn': '', 'dependState': []}}, {'name': 'units', 'data': {'type': 'arrayInt', 'default': 4, 'help': 'The number of units (hidden neurons) in the layer. Recommended value is 80. higher numbers will cause overfit.', 'url': '', 'regex': '', 'label': 'Number of Units', 'dependsOn': '', 'dependState': []}}, {'name': 'return_sequences', 'data': {'type': 'bool', 'default': False, 'help': 'If checked the layer will return all recurrent sequence values, otherwise the layer will return a list of values with same length as hidden units. \nThis feature should be checked If the next layer is another LSTM, for other cases it is recommended not to check this otherwise you should add a flatten layer after the current layer.', 'url': '', 'regex': '', 'label': 'Return Sequence', 'dependsOn': '', 'dependState': []}}, {'name': 'activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 1, 'name': 'relu', 'value': 'relu'}, {'id': 2, 'name': 'linear', 'value': 'linear'}, {'id': 3, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 4, 'name': 'softmax', 'value': 'softmax'}, {'id': 5, 'name': 'softplus', 'value': 'softplus'}, {'id': 6, 'name': 'tanh', 'value': 'tanh'}, {'id': 7, 'name': 'selu', 'value': 'selu'}, {'id': 8, 'name': 'elu', 'value': 'elu'}, {'id': 9, 'name': 'exponential', 'value': 'exponential'}], 'default': 'relu', 'help': "The activation function applies to the output of each hidden node.  Recommended option is 'ReLU (rectified linear unit)' as it handles all positive data ranges. Remember that the functions “sigmoid“ and “tanh“ will limit the range to (-1, 1) and should not be used when data is not normalized.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_activation', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'relu', 'value': 'relu'}, {'id': 0, 'name': 'linear', 'value': 'linear'}, {'id': 0, 'name': 'sigmoid', 'value': 'sigmoid'}, {'id': 0, 'name': 'softmax', 'value': 'softmax'}, {'id': 0, 'name': 'softplus', 'value': 'softplus'}, {'id': 0, 'name': 'tanh', 'value': 'tanh'}, {'id': 0, 'name': 'selu', 'value': 'selu'}, {'id': 0, 'name': 'elu', 'value': 'elu'}, {'id': 0, 'name': 'exponential', 'value': 'exponential'}], 'default': 'tanh', 'help': 'The activation function applies to the output of each hidden node for recurrence. It is strongly recommended to use activations within range of (-1, 1) like sigmoid or  tanh.', 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Activation Function', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_dropout', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'Choose the rate of dropout on recurrence. The fraction or percentage of the nodes from the recurrsion to be dropped. The recommended value is 0, it is strongly recommended not to choose values more than 0.5, the range of this attribute is (0, 1).', 'url': '', 'regex': '', 'label': 'Recurrent Drop Out', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nRecommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Kernel Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'kernel_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for weight matrix. Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Kernel Initializer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l1', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L1 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L1 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L1 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_regularizer_l2', 'data': {'type': 'arrayInt', 'default': 0, 'help': 'This L2 Regularizer Coefficient is the penalty that prevents higher weight values. This field specifies the L2 regularizer coefficient for recurrsion. When the model is complex, there is higher risk of overfitting, and this coefficient can help to decrease this risk. \n \nValue should be in range (0, 1). Recommended value is 0. Large regularizer coefficients will prevent the AI model to modify weights far from zero, causing underfitting.', 'url': '', 'regex': '', 'label': 'L2 Recurrent Regularizer', 'dependsOn': '', 'dependState': []}}, {'name': 'recurrent_initializer', 'data': {'type': 'singleMultiple', 'values': [{'id': 0, 'name': 'zeros', 'value': '{"class_name":"Zeros","config":{}}'}, {'id': 1, 'name': 'ones', 'value': '{"class_name":"Ones","config":{}}'}, {'id': 2, 'name': 'random_normal', 'value': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}'}, {'id': 3, 'name': 'random_uniform', 'value': '{"class_name":"RandomUniform","config":{"minval":-0.05,"maxval":0.05,"seed":null}}'}, {'id': 4, 'name': 'glorot_normal', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"uniform","seed":null}}'}, {'id': 5, 'name': 'glorot_uniform', 'value': '{"class_name":"VarianceScaling","config":{"scale":1,"mode":"fan_avg","distribution":"normal","seed":null}}'}, {'id': 6, 'name': 'orthogonal', 'value': '{"class_name":"Orthogonal","config":{"gain":1,"seed":null}}'}], 'default': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'help': "Choose the initialization method for recurrsion weights.  Recommended method is 'random_normal'. Note that the kernel initializere is very critical when the model uses small number of epochs and we recommend to proceed by trial and error if need be.", 'url': '', 'regex': '', 'multiple': False, 'label': 'Recurrent Initializer', 'dependsOn': '', 'dependState': []}}], 'data': {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'recurrent_initializer': '{"class_name":"RandomNormal","config":{"mean":0,"stddev":0.05,"seed":null}}', 'kernel_regularizer': None, 'kernel_regularizer_l1': 0, 'kernel_regularizer_l2': 0, 'recurrent_regularizer': None, 'recurrent_regularizer_l1': 0, 'recurrent_regularizer_l2': 0, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}}}, 'header': 'Recurrent Layers'}, 'cssClass': 'TooltipFigure', 'ports': [], 'bgColor': 'rgba(255,255,255,1)', 'color': 'rgba(0,0,0,1)', 'stroke': 0, 'radius': 5, 'dasharray': None, 'text': 'LSTM', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'fontSize': 12, 'fontColor': 'rgba(0,0,0,1)', 'fontFamily': None}]}, {'type': 'draw2d.Connection', 'id': 'b5921475-520d-09dd-fca0-ccad54cd4821', 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_Connection', 'stroke': 2, 'color': 'rgba(18,156,228,1)', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'policy': 'draw2d.policy.line.LineSelectionFeedbackPolicy', 'vertex': [{'x': 674.2906494140625, 'y': 128.77500915527344}, {'x': 709.9078369140625, 'y': 128.77500915527344}, {'x': 709.9078369140625, 'y': 146.77500915527344}, {'x': 745.5250244140625, 'y': 146.77500915527344}], 'router': 'draw2d.layout.connection.ManhattanBridgedConnectionRouter', 'radius': 3, 'source': {'node': 'e435eebb-c80a-454f-8377-04a7194a2468', 'port': 'output'}, 'target': {'node': 'f67845b6-0fe9-47c2-8239-763e482fedc4', 'port': 'input0', 'decoration': 'draw2d.decoration.connection.ArrowDecorator'}}, {'type': 'draw2d.Connection', 'id': '0d4e69b3-e26a-dc08-4b61-c695a5b7650e', 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_Connection', 'stroke': 2, 'color': 'rgba(18,156,228,1)', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'policy': 'draw2d.policy.line.LineSelectionFeedbackPolicy', 'vertex': [{'x': 519.9781494140625, 'y': 136.07501220703125}, {'x': 555.2515869140625, 'y': 136.07501220703125}, {'x': 555.2515869140625, 'y': 128.77500915527344}, {'x': 590.5250244140625, 'y': 128.77500915527344}], 'router': 'draw2d.layout.connection.ManhattanBridgedConnectionRouter', 'radius': 3, 'source': {'node': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'port': 'output'}, 'target': {'node': 'e435eebb-c80a-454f-8377-04a7194a2468', 'port': 'input0', 'decoration': 'draw2d.decoration.connection.ArrowDecorator'}}, {'type': 'draw2d.Connection', 'id': 'e8665e8e-c77b-ffae-4c38-3a071e9d7027', 'alpha': 1, 'selectable': True, 'draggable': True, 'angle': 0, 'userData': {}, 'cssClass': 'draw2d_Connection', 'stroke': 2, 'color': 'rgba(18,156,228,1)', 'outlineStroke': 0, 'outlineColor': 'rgba(0,0,0,0)', 'policy': 'draw2d.policy.line.LineSelectionFeedbackPolicy', 'vertex': [{'x': 98.546875, 'y': 48.625}, {'x': 254.03594970703125, 'y': 48.625}, {'x': 254.03594970703125, 'y': 136.07501220703125}, {'x': 409.5250244140625, 'y': 136.07501220703125}], 'router': 'draw2d.layout.connection.ManhattanBridgedConnectionRouter', 'radius': 3, 'source': {'node': '123a71f6-989b-4440-81a4-b02e0c4db40d', 'port': 'output'}, 'target': {'node': '25d00656-2dfc-43c5-ae2c-144a76e554f7', 'port': 'input0', 'decoration': 'draw2d.decoration.connection.ArrowDecorator'}}], 'model_structure': {'class_name': 'Model', 'config': {'name': 'model', 'layers': [{'name': 'Dense', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense', 'units': 5, 'activation': 'relu', 'kernel_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0, 'stddev': 0.05, 'seed': None}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0, 'l2': 0}}}, 'inbound_nodes': [[['LSTM', 0, 0]]]}, {'name': 'Dense2', 'class_name': 'Dense', 'type': 'Deep', 'layer': 'Core Layers', 'config': {'name': 'Dense2', 'units': 1, 'activation': 'softmax', 'kernel_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0, 'stddev': 0.05, 'seed': None}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0, 'l2': 0}}}, 'inbound_nodes': [[['Dense', 0, 0]]]}, {'name': 'LSTM', 'class_name': 'LSTM', 'type': 'Deep', 'layer': 'Recurrent Layers', 'config': {'name': 'LSTM', 'return_sequences': False, 'units': 4, 'activation': 'relu', 'recurrent_activation': 'tanh', 'kernel_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0, 'stddev': 0.05, 'seed': None}}, 'recurrent_initializer': {'class_name': 'RandomNormal', 'config': {'mean': 0, 'stddev': 0.05, 'seed': None}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0, 'l2': 0}}, 'recurrent_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0, 'l2': 0}}, 'recurrent_dropout': 0, 'implementation': 2}, 'inbound_nodes': [[]]}], 'input_layers': [], 'output_layers': [['Dense2', 0, 0]]}}, 'model_config': {'name': 'deepModelGeneral', 'epoch': 10, 'batch_size': 32, 'training_function': 'adam', 'loss_function': 'mse', 'seed': 0, 'window_size': 1, 'shuffle': False, 'validation_split': 0, 'learning_rate': 0.001}, 'model_type': 'Deep', 'Input_structure': [{'data_frame': 'Input', 'inputs': ['LSTM']}]}
